{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c5fa8a",
   "metadata": {},
   "source": [
    "# Create Athena Tables for Flight Data\n",
    "\n",
    "**AAI-540 Group 1 - Flight Delay Prediction Project**\n",
    "\n",
    "## Objective\n",
    "Set up AWS Athena to catalog and query our flight delay dataset:\n",
    "1. Create Athena database\n",
    "2. Create external tables for flights, airlines, and airports\n",
    "3. Verify tables with test queries\n",
    "\n",
    "## Why Athena?\n",
    "- Query S3 data directly without loading into a database\n",
    "- Standard SQL interface\n",
    "- Serverless and cost-effective\n",
    "- Integrates with AWS Glue Data Catalog\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03a55e",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "Import required libraries and load project configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9a5f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "============================================================\n",
      "AAI-540 Group 1 Project Configuration\n",
      "============================================================\n",
      "Region: us-east-1\n",
      "S3 Bucket: sagemaker-us-east-1-786869526001\n",
      "Project Prefix: aai540-group1/\n",
      "Athena Database: aai540_group1_db\n",
      "\n",
      "S3 Base URI: s3://sagemaker-us-east-1-786869526001/aai540-group1/\n",
      "============================================================\n",
      "\n",
      "Notebook executed at: 2026-01-23 08:03:05\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project configuration\n",
    "from config import settings\n",
    "\n",
    "# Display configuration\n",
    "settings.print_config()\n",
    "\n",
    "print(f\"\\nNotebook executed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247619a3",
   "metadata": {},
   "source": [
    "## 2. Initialize Athena Client\n",
    "\n",
    "Set up boto3 Athena client and verify S3 data location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a28db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athena Configuration:\n",
      "======================================================================\n",
      "Database Name: aai540_group1_db\n",
      "Raw Data Location: s3://sagemaker-us-east-1-786869526001/aai540-group1/data/raw/\n",
      "Tables Location: s3://sagemaker-us-east-1-786869526001/aai540-group1/data/tables/\n",
      "Athena Staging: s3://sagemaker-us-east-1-786869526001/aai540-group1/athena/staging/\n",
      "======================================================================\n",
      "\n",
      "Verifying S3 raw data location...\n",
      "✓ Found 3 files in s3://sagemaker-us-east-1-786869526001/aai540-group1/data/raw/\n",
      "  - airlines.csv\n",
      "  - airports.csv\n",
      "  - flights.csv\n",
      "\n",
      "Organizing data into table directories...\n",
      "  Copying airlines.csv -> tables/airlines/\n",
      "  ✓ Created tables/airlines/\n",
      "  Copying airports.csv -> tables/airports/\n",
      "  ✓ Created tables/airports/\n",
      "  Copying flights.csv -> tables/flights/\n",
      "  ✓ Created tables/flights/\n",
      "\n",
      "✓ Data organized for Athena tables!\n"
     ]
    }
   ],
   "source": [
    "# Initialize AWS clients\n",
    "athena_client = boto3.client('athena', region_name=settings.REGION)\n",
    "s3_client = boto3.client('s3', region_name=settings.REGION)\n",
    "\n",
    "# Get configuration values\n",
    "bucket_name = settings.DEFAULT_BUCKET\n",
    "database_name = settings.ATHENA_DATABASE\n",
    "raw_data_uri = settings.S3_PATHS['raw_data']\n",
    "athena_staging_uri = settings.S3_PATHS['athena_staging']\n",
    "\n",
    "# Define table locations (directories, not files)\n",
    "tables_base_uri = f\"s3://{bucket_name}/aai540-group1/data/tables\"\n",
    "\n",
    "print(\"Athena Configuration:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Database Name: {database_name}\")\n",
    "print(f\"Raw Data Location: {raw_data_uri}\")\n",
    "print(f\"Tables Location: {tables_base_uri}/\")\n",
    "print(f\"Athena Staging: {athena_staging_uri}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verify S3 raw data exists\n",
    "print(f\"\\nVerifying S3 raw data location...\")\n",
    "s3_prefix = raw_data_uri.replace(f's3://{bucket_name}/', '')\n",
    "\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=s3_prefix, MaxKeys=5)\n",
    "\n",
    "if 'Contents' in response:\n",
    "    print(f\"✓ Found {len(response['Contents'])} files in {raw_data_uri}\")\n",
    "    for obj in response['Contents']:\n",
    "        print(f\"  - {obj['Key'].split('/')[-1]}\")\n",
    "else:\n",
    "    print(f\"✗ No files found in {raw_data_uri}\")\n",
    "    print(\"⚠ Please run 01_setup_s3_and_ingest.ipynb first!\")\n",
    "\n",
    "# Copy CSV files to table-specific directories (Athena works better with directories)\n",
    "print(f\"\\nOrganizing data into table directories...\")\n",
    "file_table_map = {\n",
    "    'airlines.csv': 'airlines',\n",
    "    'airports.csv': 'airports', \n",
    "    'flights.csv': 'flights'\n",
    "}\n",
    "\n",
    "for file_name, table_name in file_table_map.items():\n",
    "    source_key = f\"aai540-group1/data/raw/{file_name}\"\n",
    "    dest_key = f\"aai540-group1/data/tables/{table_name}/{file_name}\"\n",
    "    \n",
    "    # Check if already copied\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=dest_key)\n",
    "        print(f\"  ✓ {table_name}/ already exists\")\n",
    "    except:\n",
    "        print(f\"  Copying {file_name} -> tables/{table_name}/\")\n",
    "        s3_client.copy_object(\n",
    "            Bucket=bucket_name,\n",
    "            CopySource={'Bucket': bucket_name, 'Key': source_key},\n",
    "            Key=dest_key\n",
    "        )\n",
    "        print(f\"  ✓ Created tables/{table_name}/\")\n",
    "\n",
    "print(f\"\\n✓ Data organized for Athena tables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d363e4",
   "metadata": {},
   "source": [
    "## 3. Create Athena Database\n",
    "\n",
    "Create a database in the AWS Glue Data Catalog for organizing our tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecb18a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Athena Database...\n",
      "======================================================================\n",
      "Database: aai540_group1_db\n",
      "Location: s3://sagemaker-us-east-1-786869526001/aai540-group1/data/raw/\n",
      "======================================================================\n",
      "\n",
      "✓ Database 'aai540_group1_db' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "print(\"Creating Athena Database...\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Database: {database_name}\")\n",
    "print(f\"Location: {settings.S3_PATHS['raw_data']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Create database using awswrangler (handles all the polling automatically)\n",
    "    wr.catalog.create_database(\n",
    "        name=database_name,\n",
    "        exist_ok=True,  # Don't fail if database already exists\n",
    "        description='AAI-540 Group 1 Flight Delay Prediction Database'\n",
    "    )\n",
    "    print(f\"\\n✓ Database '{database_name}' created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error creating database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0faca66",
   "metadata": {},
   "source": [
    "## 4. Create External Tables\n",
    "\n",
    "Create external tables pointing to the CSV files in S3. We'll start with the simplest table first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868509ec",
   "metadata": {},
   "source": [
    "### 4.1 Create Airlines Table\n",
    "\n",
    "2 columns: IATA_CODE (string), AIRLINE (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "715fa8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating airlines table...\n",
      "S3 Location: s3://sagemaker-us-east-1-786869526001/aai540-group1/data/tables/airlines/\n",
      "✓ Airlines table created successfully!\n",
      "\n",
      "Sample data (5 rows):\n",
      "  iata_code                 airline\n",
      "0        UA   United Air Lines Inc.\n",
      "1        AA  American Airlines Inc.\n",
      "2        US         US Airways Inc.\n",
      "3        F9  Frontier Airlines Inc.\n",
      "4        B6         JetBlue Airways\n"
     ]
    }
   ],
   "source": [
    "# Create airlines table using raw DDL with OpenCSVSerde\n",
    "airlines_location = f\"{tables_base_uri}/airlines/\"\n",
    "\n",
    "print(\"Creating airlines table...\")\n",
    "print(f\"S3 Location: {airlines_location}\")\n",
    "\n",
    "# Drop existing table first\n",
    "wr.catalog.delete_table_if_exists(database=database_name, table='airlines')\n",
    "\n",
    "# Create table with OpenCSVSerde for proper CSV parsing\n",
    "airlines_ddl = f\"\"\"\n",
    "CREATE EXTERNAL TABLE {database_name}.airlines (\n",
    "    IATA_CODE STRING,\n",
    "    AIRLINE STRING\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "    'separatorChar' = ',',\n",
    "    'quoteChar' = '\"'\n",
    ")\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '{airlines_location}'\n",
    "TBLPROPERTIES ('skip.header.line.count' = '1')\n",
    "\"\"\"\n",
    "\n",
    "wr.athena.read_sql_query(\n",
    "    sql=airlines_ddl,\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "\n",
    "print(\"✓ Airlines table created successfully!\")\n",
    "\n",
    "# Verify with sample\n",
    "df_airlines_sample = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT * FROM {database_name}.airlines LIMIT 5\",\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "print(f\"\\nSample data ({len(df_airlines_sample)} rows):\")\n",
    "print(df_airlines_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696c949",
   "metadata": {},
   "source": [
    "### 4.2 Create Airports Table\n",
    "\n",
    "7 columns: IATA_CODE, AIRPORT, CITY, STATE, COUNTRY, LATITUDE, LONGITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78eeb4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating airports table...\n",
      "S3 Location: s3://sagemaker-us-east-1-786869526001/aai540-group1/data/tables/airports/\n",
      "✓ Airports table created successfully!\n",
      "\n",
      "Sample data (5 rows):\n",
      "  iata_code                              airport         city state country  \\\n",
      "0       ABE  Lehigh Valley International Airport    Allentown    PA     USA   \n",
      "1       ABI             Abilene Regional Airport      Abilene    TX     USA   \n",
      "2       ABQ    Albuquerque International Sunport  Albuquerque    NM     USA   \n",
      "3       ABR            Aberdeen Regional Airport     Aberdeen    SD     USA   \n",
      "4       ABY   Southwest Georgia Regional Airport       Albany    GA     USA   \n",
      "\n",
      "   latitude   longitude  \n",
      "0  40.65236   -75.44040  \n",
      "1  32.41132   -99.68190  \n",
      "2  35.04022  -106.60919  \n",
      "3  45.44906   -98.42183  \n",
      "4  31.53552   -84.19447  \n"
     ]
    }
   ],
   "source": [
    "# Create airports table using raw DDL with OpenCSVSerde\n",
    "airports_location = f\"{tables_base_uri}/airports/\"\n",
    "\n",
    "print(\"Creating airports table...\")\n",
    "print(f\"S3 Location: {airports_location}\")\n",
    "\n",
    "# Drop existing table first\n",
    "wr.catalog.delete_table_if_exists(database=database_name, table='airports')\n",
    "\n",
    "# Create table with OpenCSVSerde for proper CSV parsing\n",
    "airports_ddl = f\"\"\"\n",
    "CREATE EXTERNAL TABLE {database_name}.airports (\n",
    "    IATA_CODE STRING,\n",
    "    AIRPORT STRING,\n",
    "    CITY STRING,\n",
    "    STATE STRING,\n",
    "    COUNTRY STRING,\n",
    "    LATITUDE STRING,\n",
    "    LONGITUDE STRING\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "    'separatorChar' = ',',\n",
    "    'quoteChar' = '\"'\n",
    ")\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '{airports_location}'\n",
    "TBLPROPERTIES ('skip.header.line.count' = '1')\n",
    "\"\"\"\n",
    "\n",
    "wr.athena.read_sql_query(\n",
    "    sql=airports_ddl,\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "\n",
    "print(\"✓ Airports table created successfully!\")\n",
    "\n",
    "# Verify with sample\n",
    "df_airports_sample = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT * FROM {database_name}.airports LIMIT 5\",\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "print(f\"\\nSample data ({len(df_airports_sample)} rows):\")\n",
    "print(df_airports_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9b7b2",
   "metadata": {},
   "source": [
    "### 4.3 Create Flights Table\n",
    "\n",
    "The main table with ~5.8M rows and 31 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48629f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flights table...\n",
      "S3 Location: s3://sagemaker-us-east-1-786869526001/aai540-group1/data/tables/flights/\n",
      "⚠ Creating table (may take a few seconds)...\n",
      "✓ Flights table created successfully!\n",
      "\n",
      "Sample data (5 rows):\n",
      "   year month day airline origin_airport destination_airport departure_delay\n",
      "0  2015     1   1      AS            ANC                 SEA             -11\n",
      "1  2015     1   1      AA            LAX                 PBI              -8\n",
      "2  2015     1   1      US            SFO                 CLT              -2\n",
      "3  2015     1   1      AA            LAX                 MIA              -5\n",
      "4  2015     1   1      AS            SEA                 ANC              -1\n"
     ]
    }
   ],
   "source": [
    "# Create flights table using raw DDL with OpenCSVSerde\n",
    "flights_location = f\"{tables_base_uri}/flights/\"\n",
    "\n",
    "print(\"Creating flights table...\")\n",
    "print(f\"S3 Location: {flights_location}\")\n",
    "\n",
    "# Drop existing table first\n",
    "wr.catalog.delete_table_if_exists(database=database_name, table='flights')\n",
    "\n",
    "# Create table with OpenCSVSerde for proper CSV parsing\n",
    "# Note: OpenCSVSerde reads all columns as STRING - we'll cast in queries as needed\n",
    "flights_ddl = f\"\"\"\n",
    "CREATE EXTERNAL TABLE {database_name}.flights (\n",
    "    YEAR STRING,\n",
    "    MONTH STRING,\n",
    "    DAY STRING,\n",
    "    DAY_OF_WEEK STRING,\n",
    "    AIRLINE STRING,\n",
    "    FLIGHT_NUMBER STRING,\n",
    "    TAIL_NUMBER STRING,\n",
    "    ORIGIN_AIRPORT STRING,\n",
    "    DESTINATION_AIRPORT STRING,\n",
    "    SCHEDULED_DEPARTURE STRING,\n",
    "    DEPARTURE_TIME STRING,\n",
    "    DEPARTURE_DELAY STRING,\n",
    "    TAXI_OUT STRING,\n",
    "    WHEELS_OFF STRING,\n",
    "    SCHEDULED_TIME STRING,\n",
    "    ELAPSED_TIME STRING,\n",
    "    AIR_TIME STRING,\n",
    "    DISTANCE STRING,\n",
    "    WHEELS_ON STRING,\n",
    "    TAXI_IN STRING,\n",
    "    SCHEDULED_ARRIVAL STRING,\n",
    "    ARRIVAL_TIME STRING,\n",
    "    ARRIVAL_DELAY STRING,\n",
    "    DIVERTED STRING,\n",
    "    CANCELLED STRING,\n",
    "    CANCELLATION_REASON STRING,\n",
    "    AIR_SYSTEM_DELAY STRING,\n",
    "    SECURITY_DELAY STRING,\n",
    "    AIRLINE_DELAY STRING,\n",
    "    LATE_AIRCRAFT_DELAY STRING,\n",
    "    WEATHER_DELAY STRING\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "    'separatorChar' = ',',\n",
    "    'quoteChar' = '\"'\n",
    ")\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '{flights_location}'\n",
    "TBLPROPERTIES ('skip.header.line.count' = '1')\n",
    "\"\"\"\n",
    "\n",
    "print(\"⚠ Creating table (may take a few seconds)...\")\n",
    "\n",
    "wr.athena.read_sql_query(\n",
    "    sql=flights_ddl,\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "\n",
    "print(\"✓ Flights table created successfully!\")\n",
    "\n",
    "# Verify with sample (Athena returns lowercase column names)\n",
    "df_flights_sample = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT * FROM {database_name}.flights LIMIT 5\",\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "print(f\"\\nSample data ({len(df_flights_sample)} rows):\")\n",
    "print(df_flights_sample[['year', 'month', 'day', 'airline', 'origin_airport', 'destination_airport', 'departure_delay']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2e95a",
   "metadata": {},
   "source": [
    "## 5. Verify Tables with Test Queries\n",
    "\n",
    "Run sample queries to verify all tables are accessible and queryable via Athena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d538b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying table row counts...\n",
      "======================================================================\n",
      "✓ Airlines table: 14 rows\n",
      "✓ Airports table: 322 rows\n",
      "\n",
      "⚠ Counting flights rows (may take 10-15 seconds)...\n",
      "✓ Flights table: 5,819,079 rows\n",
      "\n",
      "======================================================================\n",
      "✓ All tables created and queryable via Athena!\n",
      "\n",
      "Task 2 Complete: Athena tables are set up for cataloging and querying data.\n"
     ]
    }
   ],
   "source": [
    "# Test query: Count rows in each table\n",
    "print(\"Verifying table row counts...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Airlines\n",
    "df_airlines_count = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT COUNT(*) as total FROM {database_name}.airlines\",\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "print(f\"✓ Airlines table: {df_airlines_count['total'][0]} rows\")\n",
    "\n",
    "# Airports  \n",
    "df_airports_count = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT COUNT(*) as total FROM {database_name}.airports\",\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "print(f\"✓ Airports table: {df_airports_count['total'][0]} rows\")\n",
    "\n",
    "# Flights (full count - may take a few seconds)\n",
    "print(\"\\n⚠ Counting flights rows (may take 10-15 seconds)...\")\n",
    "df_flights_count = wr.athena.read_sql_query(\n",
    "    sql=f\"SELECT COUNT(*) as total FROM {database_name}.flights\",\n",
    "    database=database_name,\n",
    "    ctas_approach=False\n",
    ")\n",
    "print(f\"✓ Flights table: {df_flights_count['total'][0]:,} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ All tables created and queryable via Athena!\")\n",
    "print(\"\\nTask 2 Complete: Athena tables are set up for cataloging and querying data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
